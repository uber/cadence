(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{419:function(t,e,a){"use strict";a.r(e);var r=a(8),s=Object(r.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"storage-scan"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#storage-scan"}},[t._v("#")]),t._v(" Storage scan")]),t._v(" "),a("p",[t._v("It is common to have large data sets partitioned across a large number of hosts or databases, or having billions of files in an Amazon S3 bucket.\nCadence is an ideal solution for implementing the full scan of such data in a scalable and resilient way. The standard pattern\nis to run an "),a("Term",{attrs:{term:"activity"}}),t._v(" (or multiple parallel "),a("Term",{attrs:{term:"activity",show:"activities"}}),t._v(" for partitioned data sets) that performs the scan and heartbeats its progress\nback to Cadence. In the case of a host failure, the "),a("Term",{attrs:{term:"activity"}}),t._v(" is retried on a different host and continues execution from the last reported progress.")],1),t._v(" "),a("p",[t._v("A real-world example:")]),t._v(" "),a("ul",[a("li",[t._v("Cadence internal system "),a("Term",{attrs:{term:"workflow"}}),t._v(" that performs periodic scan of all "),a("Term",{attrs:{term:"workflow_execution"}}),t._v(" records")],1)])])}),[],!1,null,null,null);e.default=s.exports}}]);